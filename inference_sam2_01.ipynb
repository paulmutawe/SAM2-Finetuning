{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c1f5bc9f-3c7c-4be8-a1e1-21628cf22221",
      "metadata": {
        "id": "c1f5bc9f-3c7c-4be8-a1e1-21628cf22221",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47258e0f-28e9-4252-c4eb-bd896c30eb5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'segment-anything-2' already exists and is not an empty directory.\n",
            "/content/segment-anything-2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "#%cd segment-anything-2\n",
        "# clone SAM2\n",
        "!git clone https://github.com/facebookresearch/segment-anything-2\n",
        "%cd segment-anything-2\n",
        "!pip install -q -e .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get your kaggle.json file from kaggle settings and place it in this directory\n",
        "!pip install kaggle\n",
        "!kaggle datasets download -d ankanghosh651/leaf-sengmentation-dataset-sam2-format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5AHtuPimSCl",
        "outputId": "25ff4100-4ab5-4780-8702-a4fa6af7de72"
      },
      "id": "C5AHtuPimSCl",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.10)\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/ankanghosh651/leaf-sengmentation-dataset-sam2-format\n",
            "License(s): MIT\n",
            "leaf-sengmentation-dataset-sam2-format.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! sudo apt-get install zip unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDXv9jCTmVX-",
        "outputId": "28890313-5256-445b-d455-69af3c988821"
      },
      "id": "PDXv9jCTmVX-",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "zip is already the newest version (3.0-12build2).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip leaf-sengmentation-dataset-sam2-format.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J3T8y-3Y1If",
        "outputId": "bbfce15d-612f-4906-b9a3-d2b62ba345c3"
      },
      "id": "1J3T8y-3Y1If",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  leaf-sengmentation-dataset-sam2-format.zip\n",
            "replace leaf-seg/images/00000.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O sam2_hiera_tiny.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt\"\n",
        "!wget -O sam2_hiera_small.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt\"\n",
        "!wget -O sam2_hiera_base_plus.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt\"\n",
        "!wget -O sam2_hiera_large.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\""
      ],
      "metadata": {
        "id": "pkXzFMeFY3R9"
      },
      "id": "pkXzFMeFY3R9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd segment-anything-2"
      ],
      "metadata": {
        "id": "q15p6Xq3ayX7"
      },
      "id": "q15p6Xq3ayX7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "763d6487-e8c9-46a0-bc53-a8f1540cdfa1",
      "metadata": {
        "id": "763d6487-e8c9-46a0-bc53-a8f1540cdfa1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn.utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88dff1af-c94b-4473-9d40-268a340f1d47",
      "metadata": {
        "id": "88dff1af-c94b-4473-9d40-268a340f1d47"
      },
      "outputs": [],
      "source": [
        "# Path to the dataset folder\n",
        "data_dir = \"../leaf-seg\"\n",
        "images_dir = os.path.join(data_dir, \"images\")\n",
        "masks_dir = os.path.join(data_dir, \"masks\")\n",
        "\n",
        "# Load the train.csv file\n",
        "train_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
        "\n",
        "# Split the data into two halves: one for training and one for testing\n",
        "train_df, test_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Prepare the training data list\n",
        "train_data = []\n",
        "for index, row in train_df.iterrows():\n",
        "   image_name = row['imageid']\n",
        "   mask_name = row['maskid']\n",
        "\n",
        "   # Append image and corresponding mask paths\n",
        "   train_data.append({\n",
        "       \"image\": os.path.join(images_dir, image_name),\n",
        "       \"annotation\": os.path.join(masks_dir, mask_name)\n",
        "   })\n",
        "\n",
        "# Prepare the testing data list (if needed for inference or evaluation later)\n",
        "test_data = []\n",
        "for index, row in test_df.iterrows():\n",
        "   image_name = row['imageid']\n",
        "   mask_name = row['maskid']\n",
        "\n",
        "   # Append image and corresponding mask paths\n",
        "   test_data.append({\n",
        "       \"image\": os.path.join(images_dir, image_name),\n",
        "       \"annotation\": os.path.join(masks_dir, mask_name)\n",
        "   })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0317fd9e-3007-44f1-99a3-ca7f04342a67",
      "metadata": {
        "id": "0317fd9e-3007-44f1-99a3-ca7f04342a67"
      },
      "outputs": [],
      "source": [
        "def read_batch(data, visualize_data=True):\n",
        "   # Select a random entry\n",
        "   ent = data[np.random.randint(len(data))]\n",
        "\n",
        "   # Get full paths\n",
        "   Img = cv2.imread(ent[\"image\"])[..., ::-1]  # Convert BGR to RGB\n",
        "   ann_map = cv2.imread(ent[\"annotation\"], cv2.IMREAD_GRAYSCALE)  # Read annotation as grayscale\n",
        "\n",
        "   if Img is None or ann_map is None:\n",
        "       print(f\"Error: Could not read image or mask from path {ent['image']} or {ent['annotation']}\")\n",
        "       return None, None, None, 0\n",
        "\n",
        "   # Resize image and mask\n",
        "   r = np.min([1024 / Img.shape[1], 1024 / Img.shape[0]])  # Scaling factor\n",
        "   Img = cv2.resize(Img, (int(Img.shape[1] * r), int(Img.shape[0] * r)))\n",
        "   ann_map = cv2.resize(ann_map, (int(ann_map.shape[1] * r), int(ann_map.shape[0] * r)), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "   ### Continuation of read_batch() ###\n",
        "\n",
        "   # Initialize a single binary mask\n",
        "   binary_mask = np.zeros_like(ann_map, dtype=np.uint8)\n",
        "   points = []\n",
        "\n",
        "   # Get binary masks and combine them into a single mask\n",
        "   inds = np.unique(ann_map)[1:]  # Skip the background (index 0)\n",
        "   for ind in inds:\n",
        "       mask = (ann_map == ind).astype(np.uint8)  # Create binary mask for each unique index\n",
        "       binary_mask = np.maximum(binary_mask, mask)  # Combine with the existing binary mask\n",
        "\n",
        "   # Erode the combined binary mask to avoid boundary points\n",
        "   eroded_mask = cv2.erode(binary_mask, np.ones((5, 5), np.uint8), iterations=1)\n",
        "\n",
        "   # Get all coordinates inside the eroded mask and choose a random point\n",
        "   coords = np.argwhere(eroded_mask > 0)\n",
        "   if len(coords) > 0:\n",
        "       for _ in inds:  # Select as many points as there are unique labels\n",
        "           yx = np.array(coords[np.random.randint(len(coords))])\n",
        "           points.append([yx[1], yx[0]])  # Corrected order for y, x\n",
        "\n",
        "   points = np.array(points)\n",
        "\n",
        "   ### Continuation of read_batch() ###\n",
        "\n",
        "   if visualize_data:\n",
        "       # Plotting the images and points\n",
        "       plt.figure(figsize=(15, 5))\n",
        "\n",
        "       # Original Image\n",
        "       plt.subplot(1, 3, 1)\n",
        "       plt.title('Original Image')\n",
        "       plt.imshow(Img)\n",
        "       plt.axis('off')\n",
        "\n",
        "       # Segmentation Mask (binary_mask)\n",
        "       plt.subplot(1, 3, 2)\n",
        "       plt.title('Binarized Mask')\n",
        "       plt.imshow(binary_mask, cmap='gray')\n",
        "       plt.axis('off')\n",
        "\n",
        "       # Mask with Points in Different Colors\n",
        "       plt.subplot(1, 3, 3)\n",
        "       plt.title('Binarized Mask with Points')\n",
        "       plt.imshow(binary_mask, cmap='gray')\n",
        "\n",
        "       # Plot points in different colors\n",
        "       colors = list(mcolors.TABLEAU_COLORS.values())\n",
        "       for i, point in enumerate(points):\n",
        "           plt.scatter(point[0], point[1], c=colors[i % len(colors)], s=100, label=f'Point {i+1}')  # Corrected to plot y, x order\n",
        "\n",
        "       # plt.legend()\n",
        "       plt.axis('off')\n",
        "\n",
        "       plt.tight_layout()\n",
        "       plt.show()\n",
        "\n",
        "   binary_mask = np.expand_dims(binary_mask, axis=-1)  # Now shape is (1024, 1024, 1)\n",
        "   binary_mask = binary_mask.transpose((2, 0, 1))\n",
        "   points = np.expand_dims(points, axis=1)\n",
        "\n",
        "   # Return the image, binarized mask, points, and number of masks\n",
        "   return Img, binary_mask, points, len(inds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "684351c4-6aa0-4cf3-be8a-19a12e634ea8",
      "metadata": {
        "id": "684351c4-6aa0-4cf3-be8a-19a12e634ea8"
      },
      "outputs": [],
      "source": [
        "def read_image(image_path, mask_path):  # read and resize image and mask\n",
        "   img = cv2.imread(image_path)[..., ::-1]  # Convert BGR to RGB\n",
        "   mask = cv2.imread(mask_path, 0)\n",
        "   r = np.min([1024 / img.shape[1], 1024 / img.shape[0]])\n",
        "   img = cv2.resize(img, (int(img.shape[1] * r), int(img.shape[0] * r)))\n",
        "   mask = cv2.resize(mask, (int(mask.shape[1] * r), int(mask.shape[0] * r)), interpolation=cv2.INTER_NEAREST)\n",
        "   return img, mask\n",
        "\n",
        "def get_points(mask, num_points):  # Sample points inside the input mask\n",
        "   points = []\n",
        "   coords = np.argwhere(mask > 0)\n",
        "   for i in range(num_points):\n",
        "       yx = np.array(coords[np.random.randint(len(coords))])\n",
        "       points.append([[yx[1], yx[0]]])\n",
        "   return np.array(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a9a9532-7dc2-4b09-bbfd-ea02d52d4734",
      "metadata": {
        "id": "8a9a9532-7dc2-4b09-bbfd-ea02d52d4734"
      },
      "outputs": [],
      "source": [
        "# Randomly select a test image from the test_data\n",
        "selected_entry = random.choice(test_data)\n",
        "# print(selected_entry)\n",
        "image_path = selected_entry['image']\n",
        "mask_path = selected_entry['annotation']\n",
        "# print(mask_path,'mask path')\n",
        "\n",
        "# Load the selected image and mask\n",
        "image, target_mask = read_image(image_path, mask_path)\n",
        "\n",
        "# Generate random points for the input\n",
        "num_samples = 30  # Number of points per segment to sample\n",
        "input_points = get_points(target_mask, num_samples)\n",
        "\n",
        "sam2_checkpoint = \"/content/sam2_hiera_tiny.pt\"  # @param [\"sam2_hiera_tiny.pt\", \"sam2_hiera_small.pt\", \"sam2_hiera_base_plus.pt\", \"sam2_hiera_large.pt\"]\n",
        "model_cfg = \"sam2_hiera_t.yaml\" # @param [\"sam2_hiera_t.yaml\", \"sam2_hiera_s.yaml\", \"sam2_hiera_b+.yaml\", \"sam2_hiera_l.yaml\"]\n",
        "\n",
        "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
        "predictor = SAM2ImagePredictor(sam2_model)\n",
        "\n",
        "# Perform inference and predict masks\n",
        "with torch.no_grad():\n",
        "   predictor.set_image(image)\n",
        "   masks, scores, logits = predictor.predict(\n",
        "       point_coords=input_points,\n",
        "       point_labels=np.ones([input_points.shape[0], 1])\n",
        "   )\n",
        "\n",
        "# Process the predicted masks and sort by scores\n",
        "np_masks = np.array(masks[:, 0])\n",
        "np_scores = scores[:, 0]\n",
        "sorted_masks = np_masks[np.argsort(np_scores)][::-1]\n",
        "\n",
        "# Initialize segmentation map and occupancy mask\n",
        "seg_map = np.zeros_like(sorted_masks[0], dtype=np.uint8)\n",
        "occupancy_mask = np.zeros_like(sorted_masks[0], dtype=bool)\n",
        "\n",
        "# Combine masks to create the final segmentation map\n",
        "for i in range(sorted_masks.shape[0]):\n",
        "   mask = sorted_masks[i]\n",
        "   if (mask * occupancy_mask).sum() / mask.sum() > 0.15:\n",
        "       continue\n",
        "\n",
        "   mask_bool = mask.astype(bool)\n",
        "   mask_bool[occupancy_mask] = False  # Set overlapping areas to False in the mask\n",
        "   seg_map[mask_bool] = i + 1  # Use boolean mask to index seg_map\n",
        "   occupancy_mask[mask_bool] = True  # Update occupancy_mask\n",
        "\n",
        "\n",
        "# Define the RGB color and transparency (alpha)\n",
        "color = (255, 20, 0)  # Green (Modify as needed)\n",
        "alpha = 0.6  # Transparency factor (0: fully transparent, 1: fully opaque)\n",
        "\n",
        "# Create an RGB mask with the chosen color\n",
        "colored_seg_map = np.zeros_like(image, dtype=np.uint8)\n",
        "colored_seg_map[..., 0] = color[0]  # Red channel\n",
        "colored_seg_map[..., 1] = color[1]  # Green channel\n",
        "colored_seg_map[..., 2] = color[2]  # Blue channel\n",
        "\n",
        "# Create a binary mask where segmentation is present\n",
        "mask_indices = seg_map > 0\n",
        "\n",
        "# Blend the original image and the colored mask using transparency\n",
        "image_with_mask_pt_1 = image.copy()\n",
        "image_with_mask_pt_1[mask_indices] = (\n",
        "    (1 - alpha) * image[mask_indices] + alpha * colored_seg_map[mask_indices]\n",
        ").astype(np.uint8)\n",
        "\n",
        "# Function to generate a unique output file name with a counter\n",
        "def get_unique_output_path(base_path, file_name, extension=\".png\"):\n",
        "    counter = 1\n",
        "    output_path = os.path.join(base_path, f\"{file_name}_{counter}{extension}\")\n",
        "    # Check for existing files and increment counter\n",
        "    while os.path.exists(output_path):\n",
        "        counter += 1\n",
        "        output_path = os.path.join(base_path, f\"{file_name}_{counter}{extension}\")\n",
        "    return output_path\n",
        "\n",
        "# Define the base path and file name\n",
        "base_path = \".\"  # Current directory or specify the desired folder\n",
        "file_name = \"best_model_14500.pt\"\n",
        "\n",
        "# Generate a unique output path\n",
        "output_path = get_unique_output_path(base_path, file_name)\n",
        "\n",
        "# Visualization: Create the figure and add subplots\n",
        "plt.figure(figsize=(24, 6))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.title('Test Image', fontsize=18, fontweight='bold')\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.title('Original Mask', fontsize=18, fontweight='bold')\n",
        "plt.imshow(target_mask, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.title('Predicted Mask')\n",
        "plt.imshow(seg_map, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.title('Image with Overlay Prediction', fontsize=18, fontweight='bold')\n",
        "plt.imshow(image_with_mask_pt_1)\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "# Adjust layout and save the final figure as an image\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path, dpi=300, bbox_inches='tight')  # Save with high resolution (300 DPI)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final layout saved at: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Need to run OpenCV locally on machine to prompt the diseased spots\n",
        "import cv2\n",
        "\n",
        "# A global list to store points clicked\n",
        "clicked_points = []\n",
        "\n",
        "def mouse_callback(event, x, y, flags, param):\n",
        "    # If left button clicked, append (x,y) to our list\n",
        "    if event == cv2.EVENT_LBUTTONDOWN:\n",
        "        print(f\"Clicked coords: ({x}, {y})\")\n",
        "        clicked_points.append((x,y))\n",
        "\n",
        "# Load your leaf image\n",
        "img = cv2.imread('../leaf_image.jpg')\n",
        "\n",
        "# Create a named OpenCV window\n",
        "cv2.namedWindow(\"Leaf Image\")\n",
        "\n",
        "# Set mouse callback on that window\n",
        "cv2.setMouseCallback(\"Leaf Image\", mouse_callback)\n",
        "\n",
        "print(\"Please click on the diseased spots in the image. Press 'Esc' to quit.\")\n",
        "\n",
        "while True:\n",
        "    # Display the image in a loop\n",
        "    cv2.imshow(\"Leaf Image\", img)\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "    if key == 27:  # 27 is the Esc key\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"You clicked these points:\")\n",
        "print(clicked_points)"
      ],
      "metadata": {
        "id": "WGTSL56QbCtE"
      },
      "id": "WGTSL56QbCtE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c92d3161-b651-403a-8dc5-ad9555645912",
      "metadata": {
        "id": "c92d3161-b651-403a-8dc5-ad9555645912"
      },
      "outputs": [],
      "source": [
        "# using the same selected entry to compare the the result with the same image\n",
        "image_path = \"../leaf_image.jpg\"\n",
        "#mask_path = selected_entry['annotation']\n",
        "\n",
        "#image_path = selected_entry['image']\n",
        "#mask_path = selected_entry['annotation']\n",
        "# print(mask_path,'mask path')\n",
        "\n",
        "# Load the selected image and mask\n",
        "#image, target_mask = read_image(image_path, mask_path)\n",
        "image = cv2.imread(image_path)[..., ::-1]\n",
        "image = image.copy()\n",
        "\n",
        "# Generate random points for the input\n",
        "#num_samples = 30  # Number of points per segment to sample\n",
        "#input_points = get_points(target_mask, num_samples)\n",
        "\n",
        "# Load the fine-tuned model\n",
        "FINE_TUNED_MODEL_WEIGHTS = \"../best_model_14500.pt\"\n",
        "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
        "\n",
        "# Build net and load weights\n",
        "predictor = SAM2ImagePredictor(sam2_model)\n",
        "predictor.model.load_state_dict(torch.load(FINE_TUNED_MODEL_WEIGHTS))\n",
        "\n",
        "# Perform inference and predict masks\n",
        "with torch.no_grad():\n",
        "   predictor.set_image(image)\n",
        "   masks, scores, logits = predictor.predict(\n",
        "       point_coords=input_points,\n",
        "       point_labels=np.ones([input_points.shape[0], 1])\n",
        "   )\n",
        "\n",
        "# Process the predicted masks and sort by scores\n",
        "np_masks = np.array(masks[:, 0])\n",
        "np_scores = scores[:, 0]\n",
        "sorted_masks = np_masks[np.argsort(np_scores)][::-1]\n",
        "\n",
        "# Initialize segmentation map and occupancy mask\n",
        "seg_map = np.zeros_like(sorted_masks[0], dtype=np.uint8)\n",
        "occupancy_mask = np.zeros_like(sorted_masks[0], dtype=bool)\n",
        "\n",
        "# Combine masks to create the final segmentation map\n",
        "for i in range(sorted_masks.shape[0]):\n",
        "   mask = sorted_masks[i]\n",
        "   if (mask * occupancy_mask).sum() / mask.sum() > 0.15:\n",
        "       continue\n",
        "\n",
        "   mask_bool = mask.astype(bool)\n",
        "   mask_bool[occupancy_mask] = False  # Set overlapping areas to False in the mask\n",
        "   seg_map[mask_bool] = i + 1  # Use boolean mask to index seg_map\n",
        "   occupancy_mask[mask_bool] = True  # Update occupancy_mask\n",
        "\n",
        "# Define the RGB color and transparency (alpha)\n",
        "color = (255, 20, 0)  # Green (Modify as needed)\n",
        "alpha = 0.6  # Transparency factor (0: fully transparent, 1: fully opaque)\n",
        "\n",
        "# Create an RGB mask with the chosen color\n",
        "colored_seg_map = np.zeros_like(image, dtype=np.uint8)\n",
        "colored_seg_map[..., 0] = color[0]  # Red channel\n",
        "colored_seg_map[..., 1] = color[1]  # Green channel\n",
        "colored_seg_map[..., 2] = color[2]  # Blue channel\n",
        "\n",
        "# Create a binary mask where segmentation is present\n",
        "mask_indices = seg_map > 0\n",
        "\n",
        "# Blend the original image and the colored mask using transparency\n",
        "image_with_mask_ft = image.copy()\n",
        "image_with_mask_ft[mask_indices] = (\n",
        "    (1 - alpha) * image[mask_indices] + alpha * colored_seg_map[mask_indices]\n",
        ").astype(np.uint8)\n",
        "\n",
        "# Function to generate a unique output file name with a counter\n",
        "def get_unique_output_path(base_path, file_name, extension=\".png\"):\n",
        "    counter = 1\n",
        "    output_path = os.path.join(base_path, f\"{file_name}_{counter}{extension}\")\n",
        "    # Check for existing files and increment counter\n",
        "    while os.path.exists(output_path):\n",
        "        counter += 1\n",
        "        output_path = os.path.join(base_path, f\"{file_name}_{counter}{extension}\")\n",
        "    return output_path\n",
        "\n",
        "# Define the base path and file name\n",
        "base_path = \".\"  # Current directory or specify the desired folder\n",
        "file_name = \"finetuning-sam2-pretrained-sam2-ft\"\n",
        "\n",
        "# Generate a unique output path\n",
        "output_path = get_unique_output_path(base_path, file_name)\n",
        "\n",
        "# Visualization: Create the figure and add subplots\n",
        "plt.figure(figsize=(24, 6))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.title('Test Image', fontsize=18, fontweight='bold')\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "\n",
        "#plt.subplot(1, 4, 2)\n",
        "#plt.title('Original Mask')\n",
        "#plt.imshow(target_mask, cmap='gray')\n",
        "#plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.title('Predicted Mask', fontsize=18, fontweight='bold')\n",
        "plt.imshow(seg_map, cmap='grey')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.title('Image with Overlay Prediction', fontsize=18, fontweight='bold')\n",
        "plt.imshow(image_with_mask_ft)\n",
        "plt.axis('off')\n",
        "\n",
        "# Adjust layout and save the final figure as an image\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path, dpi=300, bbox_inches='tight')  # Save with high resolution (300 DPI)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final layout saved at: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using the same selected entry to compare the the result with the same image\n",
        "\n",
        "image_path = selected_entry['image']\n",
        "mask_path = selected_entry['annotation']\n",
        "# print(mask_path,'mask path')\n",
        "\n",
        "# Load the selected image and mask\n",
        "image, target_mask = read_image(image_path, mask_path)\n",
        "\n",
        "# Generate random points for the input\n",
        "num_samples = 30  # Number of points per segment to sample\n",
        "input_points = get_points(target_mask, num_samples)\n",
        "\n",
        "# Load the fine-tuned model\n",
        "FINE_TUNED_MODEL_WEIGHTS = \"../best_model_14500.pt\"\n",
        "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
        "\n",
        "# Build net and load weights\n",
        "predictor = SAM2ImagePredictor(sam2_model)\n",
        "predictor.model.load_state_dict(torch.load(FINE_TUNED_MODEL_WEIGHTS))\n",
        "\n",
        "# Perform inference and predict masks\n",
        "with torch.no_grad():\n",
        "   predictor.set_image(image)\n",
        "   masks, scores, logits = predictor.predict(\n",
        "       point_coords=input_points,\n",
        "       point_labels=np.ones([input_points.shape[0], 1])\n",
        "   )\n",
        "\n",
        "# Process the predicted masks and sort by scores\n",
        "np_masks = np.array(masks[:, 0])\n",
        "np_scores = scores[:, 0]\n",
        "sorted_masks = np_masks[np.argsort(np_scores)][::-1]\n",
        "\n",
        "# Initialize segmentation map and occupancy mask\n",
        "seg_map = np.zeros_like(sorted_masks[0], dtype=np.uint8)\n",
        "occupancy_mask = np.zeros_like(sorted_masks[0], dtype=bool)\n",
        "\n",
        "# Combine masks to create the final segmentation map\n",
        "for i in range(sorted_masks.shape[0]):\n",
        "   mask = sorted_masks[i]\n",
        "   if (mask * occupancy_mask).sum() / mask.sum() > 0.15:\n",
        "       continue\n",
        "\n",
        "   mask_bool = mask.astype(bool)\n",
        "   mask_bool[occupancy_mask] = False  # Set overlapping areas to False in the mask\n",
        "   seg_map[mask_bool] = i + 1  # Use boolean mask to index seg_map\n",
        "   occupancy_mask[mask_bool] = True  # Update occupancy_mask\n",
        "\n",
        "# Define the RGB color and transparency (alpha)\n",
        "color = (255, 20, 0)  # Green (Modify as needed)\n",
        "alpha = 0.6  # Transparency factor (0: fully transparent, 1: fully opaque)\n",
        "\n",
        "# Create an RGB mask with the chosen color\n",
        "colored_seg_map = np.zeros_like(image, dtype=np.uint8)\n",
        "colored_seg_map[..., 0] = color[0]  # Red channel\n",
        "colored_seg_map[..., 1] = color[1]  # Green channel\n",
        "colored_seg_map[..., 2] = color[2]  # Blue channel\n",
        "\n",
        "# Create a binary mask where segmentation is present\n",
        "mask_indices = seg_map > 0\n",
        "\n",
        "# Blend the original image and the colored mask using transparency\n",
        "image_with_mask_ft = image.copy()\n",
        "image_with_mask_ft[mask_indices] = (\n",
        "    (1 - alpha) * image[mask_indices] + alpha * colored_seg_map[mask_indices]\n",
        ").astype(np.uint8)\n",
        "\n",
        "# Function to generate a unique output file name with a counter\n",
        "def get_unique_output_path(base_path, file_name, extension=\".png\"):\n",
        "    counter = 1\n",
        "    output_path = os.path.join(base_path, f\"{file_name}_{counter}{extension}\")\n",
        "    # Check for existing files and increment counter\n",
        "    while os.path.exists(output_path):\n",
        "        counter += 1\n",
        "        output_path = os.path.join(base_path, f\"{file_name}_{counter}{extension}\")\n",
        "    return output_path\n",
        "\n",
        "# Define the base path and file name\n",
        "base_path = \".\"  # Current directory or specify the desired folder\n",
        "file_name = \"finetuning-sam2-pretrained-sam2-ft\"\n",
        "\n",
        "# Generate a unique output path\n",
        "output_path = get_unique_output_path(base_path, file_name)\n",
        "\n",
        "# Visualization: Create the figure and add subplots\n",
        "plt.figure(figsize=(24, 6))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.title('Test Image', fontsize=18, fontweight='bold')\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "\n",
        "#plt.subplot(1, 4, 2)\n",
        "#plt.title('Original Mask')\n",
        "#plt.imshow(target_mask, cmap='gray')\n",
        "#plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.title('Predicted Mask', fontsize=18, fontweight='bold')\n",
        "plt.imshow(seg_map, cmap='grey')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.title('Image with Overlay Prediction', fontsize=18, fontweight='bold')\n",
        "plt.imshow(image_with_mask_ft)\n",
        "plt.axis('off')\n",
        "\n",
        "# Adjust layout and save the final figure as an image\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_path, dpi=300, bbox_inches='tight')  # Save with high resolution (300 DPI)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final layout saved at: {output_path}\")"
      ],
      "metadata": {
        "id": "GrsHPmeGf19Z"
      },
      "id": "GrsHPmeGf19Z",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}